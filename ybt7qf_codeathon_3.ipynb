{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5rzxTdvPVeECkq2+Dj9Yn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dscer/DS6050_Codeathon_3/blob/main/ybt7qf_codeathon_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install keras_nlp -q"
      ],
      "metadata": {
        "id": "PAq3Enk_8JNX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Text Generation Tutorial (Gutenberg dataset)"
      ],
      "metadata": {
        "id": "BUSyluP25lNa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BohRSi2T7ywU",
        "outputId": "a3bbcdb1-3c43-488b-931e-56d9a2ea7992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Settings & hyperparameters"
      ],
      "metadata": {
        "id": "1Yskx8jD94YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "BATCH_SIZE = 64\n",
        "SEQ_LEN = 128\n",
        "MIN_TRAINING_SEQ_LEN = 450\n",
        "\n",
        "# Model\n",
        "EMBED_DIM = 256\n",
        "FEED_FORWARD_DIM = 256\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 2\n",
        "VOCAB_SIZE = 5000  # Limits parameters in model.\n",
        "\n",
        "# Training\n",
        "EPOCHS = 6\n",
        "\n",
        "# Inference\n",
        "NUM_TOKENS_TO_GENERATE = 80"
      ],
      "metadata": {
        "id": "sRTVy-6a9Eax"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "GmSDTGNb91uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.get_file(\n",
        "    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "dir = os.path.expanduser(\"~/.keras/datasets/simplebooks/\")\n",
        "\n",
        "# Load simplebooks-92 train set and filter out short lines.\n",
        "raw_train_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/train.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(buffer_size=256)\n",
        ")\n",
        "\n",
        "# Load simplebooks-92 validation set and filter out short lines.\n",
        "raw_val_ds = (\n",
        "    tf.data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n",
        "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "uLJEEa4S8Aes",
        "outputId": "e49dbb59-47eb-4a3e-c44f-7627a8fb428a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n",
            "282386239/282386239 [==============================] - 8s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the tokenizer"
      ],
      "metadata": {
        "id": "T3VbgHCK9yzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train tokenizer vocabulary\n",
        "vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "    raw_train_ds,\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    lowercase=True,\n",
        "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
        ")"
      ],
      "metadata": {
        "id": "dShPfUwH88bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tokenizer"
      ],
      "metadata": {
        "id": "3cQwkUoO9v3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    lowercase=True,\n",
        ")"
      ],
      "metadata": {
        "id": "m0iwGCkm9Lgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize data"
      ],
      "metadata": {
        "id": "ADc9GsCo9uGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packer adds a start token\n",
        "start_packer = keras_nlp.layers.StartEndPacker(\n",
        "    sequence_length=SEQ_LEN,\n",
        "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess(inputs):\n",
        "    outputs = tokenizer(inputs)\n",
        "    features = start_packer(outputs)\n",
        "    labels = outputs\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# Tokenize and split into train and label sequences.\n",
        "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")\n",
        "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(\n",
        "    tf.data.AUTOTUNE\n",
        ")"
      ],
      "metadata": {
        "id": "kXP23Z9I9loi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model"
      ],
      "metadata": {
        "id": "-6ErYgGZ9_xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=tf.int32)\n",
        "# Embedding.\n",
        "embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")\n",
        "x = embedding_layer(inputs)\n",
        "# Transformer decoders.\n",
        "for _ in range(NUM_LAYERS):\n",
        "    decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
        "        num_heads=NUM_HEADS,\n",
        "        intermediate_dim=FEED_FORWARD_DIM,\n",
        "    )\n",
        "    x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n",
        "# Output.\n",
        "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "perplexity = keras_nlp.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[perplexity])"
      ],
      "metadata": {
        "id": "hL4yhOF49rEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oCrsybk9_JC",
        "outputId": "5559b88c-31c6-43fe-d028-aad364b177bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 256)         1312768   \n",
            " ng (TokenAndPositionEmbedd                                      \n",
            " ing)                                                            \n",
            "                                                                 \n",
            " transformer_decoder (Trans  (None, None, 256)         394749    \n",
            " formerDecoder)                                                  \n",
            "                                                                 \n",
            " transformer_decoder_1 (Tra  (None, None, 256)         394749    \n",
            " nsformerDecoder)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 5000)        1285000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3387266 (12.92 MB)\n",
            "Trainable params: 3387266 (12.92 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "XklaG5_q-M5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, validation_data=val_ds, verbose=2, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl8023gL-Ka_",
        "outputId": "a15d4da2-7d96-440d-d428-ab110b2ebb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "e4M4nRRd-Pot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"packer\" layers adds the [BOS] token for us.\n",
        "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
        "prompt_tokens"
      ],
      "metadata": {
        "id": "yijZyYCq-PA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next(prompt, cache, index):\n",
        "    logits = model(prompt)[:, index - 1, :]\n",
        "    # Ignore hidden states for now; only needed for contrastive search.\n",
        "    hidden_states = None\n",
        "    return logits, hidden_states, cache"
      ],
      "metadata": {
        "id": "zbhfwPGy-W00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Greedy search\n"
      ],
      "metadata": {
        "id": "Y7nSf113-n34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.GreedySampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,  # Start sampling immediately after the [BOS] token.\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Greedy search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "crjufEzN-k0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beam search"
      ],
      "metadata": {
        "id": "6yIJQduaBaQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.BeamSampler(num_beams=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Beam search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "rzSyMBQBBUQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random search"
      ],
      "metadata": {
        "id": "Uw6Y2b3EBebb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.RandomSampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Random search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "xKXmLRJyBcko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-K search"
      ],
      "metadata": {
        "id": "G0SnxtyABjdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.TopKSampler(k=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-K search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "WQJUxk4wBgrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top-P search\n"
      ],
      "metadata": {
        "id": "VQiyf_uABnM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = keras_nlp.samplers.TopPSampler(p=0.5)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-P search generated text: \\n{txt}\\n\")"
      ],
      "metadata": {
        "id": "vMpWgnkqBlaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using callbacks for text generation"
      ],
      "metadata": {
        "id": "LS7vQFg0B14V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TopKTextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"A callback to generate text from a trained model using top-k.\"\"\"\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.sampler = keras_nlp.samplers.TopKSampler(k)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output_tokens = self.sampler(\n",
        "            next=next,\n",
        "            prompt=prompt_tokens,\n",
        "            index=1,\n",
        "        )\n",
        "        txt = tokenizer.detokenize(output_tokens)\n",
        "        print(f\"Top-K search generated text: \\n{txt}\\n\")\n",
        "\n",
        "\n",
        "text_generation_callback = TopKTextGenerator(k=10)\n",
        "# Dummy training loop to demonstrate callback.\n",
        "model.fit(train_ds.take(1), verbose=2, epochs=2, callbacks=[text_generation_callback])"
      ],
      "metadata": {
        "id": "G7p4lP3nB0e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation with KerasNLP (Reddit dataset)\n"
      ],
      "metadata": {
        "id": "g0dW9_Hb5Cz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_nlp -q"
      ],
      "metadata": {
        "id": "VHpDP-zq_QQ4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "import time\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "De37YiUECDb1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess Reddit dataset"
      ],
      "metadata": {
        "id": "xHWhr0PF6ObJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_ds = tfds.load(\"reddit_tifu\", split=\"train\", as_supervised=True)"
      ],
      "metadata": {
        "id": "5xpl5yV-6P7Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for document, title in reddit_ds:\n",
        "    print(document.numpy())\n",
        "    print(title.numpy())\n",
        "    break"
      ],
      "metadata": {
        "id": "H1gMzGBr6UOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5367dd3f-5252-4a9d-aba0-4180821ad464"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"me and a friend decided to go to the beach last sunday. we loaded up and headed out. we were about half way there when i decided that i was not leaving till i had seafood. \\n\\nnow i'm not talking about red lobster. no friends i'm talking about a low country boil. i found the restaurant and got directions. i don't know if any of you have heard about the crab shack on tybee island but let me tell you it's worth it. \\n\\nwe arrived and was seated quickly. we decided to get a seafood sampler for two and split it. the waitress bought it out on separate platters for us. the amount of food was staggering. two types of crab, shrimp, mussels, crawfish, andouille sausage, red potatoes, and corn on the cob. i managed to finish it and some of my friends crawfish and mussels. it was a day to be a fat ass. we finished paid for our food and headed to the beach. \\n\\nfunny thing about seafood. it runs through me faster than a kenyan \\n\\nwe arrived and walked around a bit. it was about 45min since we arrived at the beach when i felt a rumble from the depths of my stomach. i ignored it i didn't want my stomach to ruin our fun. i pushed down the feeling and continued. about 15min later the feeling was back and stronger than before. again i ignored it and continued. 5min later it felt like a nuclear reactor had just exploded in my stomach. i started running. i yelled to my friend to hurry the fuck up. \\n\\nrunning in sand is extremely hard if you did not know this. we got in his car and i yelled at him to floor it. my stomach was screaming and if he didn't hurry i was gonna have this baby in his car and it wasn't gonna be pretty. after a few red lights and me screaming like a woman in labor we made it to the store. \\n\\ni practically tore his car door open and ran inside. i ran to the bathroom opened the door and barely got my pants down before the dam burst and a flood of shit poured from my ass. \\n\\ni finished up when i felt something wet on my ass. i rubbed it thinking it was back splash. no, mass was covered in the after math of me abusing the toilet. i grabbed all the paper towels i could and gave my self a whores bath right there. \\n\\ni sprayed the bathroom down with the air freshener and left. an elderly lady walked in quickly and closed the door. i was just about to walk away when i heard gag. instead of walking i ran. i got to the car and told him to get the hell out of there.\"\n",
            "b'liking seafood'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = (\n",
        "    reddit_ds.map(lambda document, _: document)\n",
        "    .batch(32)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "-UORveru6WLi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configs"
      ],
      "metadata": {
        "id": "1uLWRq8OFEgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.take(500)\n",
        "num_epochs = 1\n",
        "\n",
        "# Linearly decaying learning rate.\n",
        "learning_rate = keras.optimizers.schedules.PolynomialDecay(\n",
        "    5e-5,\n",
        "    decay_steps=train_ds.cardinality() * num_epochs,\n",
        "    end_learning_rate=0.0,\n",
        ")\n",
        "\n",
        "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "nO896XyI6ZAO"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune Pre-Trained Models"
      ],
      "metadata": {
        "id": "KopnDFSS5-K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT2"
      ],
      "metadata": {
        "id": "jjECTaI8E94W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To speed up training and generation, we use preprocessor of length 128\n",
        "# instead of full length 1024.\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")"
      ],
      "metadata": {
        "id": "5dco-t7_5-vf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "print(\"\\nGPT-2 output:\")\n",
        "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "id": "fFIbjvbY6IWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae0e013-d5cb-4254-b44f-064c4a38fe86"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "\n",
            "GPT-2 output:\n",
            "My trip to Yosemite was a bit more of a rollercoaster ride. There was so much to see, and so much to do. I had the privilege of being on the second day of the trip, and the first day of my stay.\n",
            "\n",
            "I spent the whole day in an area known as the \"Buddy's Canyon\" where the view is best known for its spectacular view of the Yosemite Valley. I spent the whole day at one of the two \"Buddy\" camps, one at the base of Mt. Zion.\n",
            "\n",
            "The other camp I stayed at is the \"Buddy's Canyon\" camp. This is a large canyon in the middle of the Sierra Nevada that is known for its breathtaking views of the mountains. It was the only place I stayed in Yosemite during the day, and it was also my last time. I spent the whole day at the \"Buddy's\" Camp.\n",
            "\n",
            "I had to leave the \"Buddy's\" camp at\n",
            "TOTAL TIME ELAPSED: 49.69s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"That Italian restaurant is\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "id": "2MhecB3a6Jhu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b74846-ac73-4ee7-c953-88cc6758b702"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[TEST] GPT-2 output:\n",
            "[TEST] That Italian restaurant is a bit more authentic than it appears, but the restaurant is still very authentic, with a good amount of food and a nice atmosphere.\n",
            "\n",
            "I've been to the Italian restaurant in the past, but never had a bad experience here. It's not like they're making a bad review here, but it's still a bit disappointing. The food was pretty good and they were very attentive. The food was also very tasty. The service was nice, but not very friendly.\n",
            "\n",
            "I've been here a couple of times and I love it, and I think it's the best restaurant in the city, but it's not the best restaurant in Italy, either. It's just not good for you.\n",
            "\n",
            "I've come here a couple of times and I'm really impressed. The food was good, and the service was very attentive. The place is pretty small, so I wouldn't recommend going there if you're a regular.\n",
            "\n",
            "[TEST] TOTAL TIME ELAPSED: 15.35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_lm.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "gpt2_lm.fit(train_ds, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1pxVWdDVHvF",
        "outputId": "10343a60-5a90-42e8-cde5-c3b02e8039f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 1s/step - accuracy: 0.3190 - loss: 3.3600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_core.src.callbacks.history.History at 0x795e14bb1540>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "\n",
        "output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "id": "4i6M2J-H6fA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58fbbf2b-7018-4155-b3e3-703dce1f339f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "I like basketball so much. it's my first time watching a game, and i've been watching it for about 3 months now. \n",
            "\n",
            "so, my mom is a freshman, so she's been watching me since i was 3 years old. so when my mom comes to the game, she says \"hey, how's the game?\" and i'm like \"i can't tell you how bad it is.\" i'm like \"well i'm gonna go play basketball, you guys are gonna be fine. it's gonna be fun. i'll be fine.\" and she goes \"yeah, you guys are gonna be fine.\" and i go \"well i'm gonna play basketball, you guys are gonna be fine.\"\n",
            "\n",
            "so, my mom comes over and tells me that she'll play basketball for me. so she\n",
            "TOTAL TIME ELAPSED: 17.75s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a string identifier.\n",
        "gpt2_lm.compile(sampler=\"top_k\")\n",
        "output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "# Use a `Sampler` instance. `GreedySampler` tends to repeat itself,\n",
        "greedy_sampler = keras_nlp.samplers.GreedySampler()\n",
        "gpt2_lm.compile(sampler=greedy_sampler)\n",
        "\n",
        "output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "GcxyXvK76jhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed816b7-39e7-4d65-c7cb-43b054cd4860"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "I like basketball. basketball, basketball, basketball, basketball, basketball. \n",
            "\n",
            "i'm a freshman in college. i play the game of basketball for a small school. i'm the most senior of the group.  i play the same game for two years, but my freshman year is the most important of my life. \n",
            "\n",
            "i play the game of basketball for the first time since high school. my freshman year was the first time that i played the game of basketball for any other school.  it was the first time that i played basketball for a college team. \n",
            "\n",
            "so i get the opportunity to play basketball.  i get to play basketball for a school that is very important.  i get to play\n",
            "\n",
            "GPT-2 output:\n",
            "I like basketball, but i don't really like the game. \n",
            "\n",
            "so i was playing basketball at my local high school, and i was playing with my friends. \n",
            "\n",
            "i was playing with my friends, and i was playing with my brother, who was playing basketball with his brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother's brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother's brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother's brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother's brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother's brother. \n",
            "\n",
            "so i was playing with my brother, and he was playing with his brother\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other GPT2-based Models"
      ],
      "metadata": {
        "id": "nSOFkvrWmVEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [\n",
        "    \"gpt2_medium_en\",\n",
        "    \"gpt2_large_en\",\n",
        "    \"gpt2_extra_large_en\",\n",
        "    \"gpt2_base_en_cnn_dailymail\"\n",
        "]\n",
        "\n",
        "for model_name in model_list:\n",
        "    preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "        model_name,\n",
        "        sequence_length=128,\n",
        "    )\n",
        "    tmp_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "        model_name, preprocessor=preprocessor\n",
        "    )\n",
        "\n",
        "    tmp_lm.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=loss,\n",
        "        weighted_metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    tmp_lm.fit(train_ds, epochs=num_epochs)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    output = tmp_lm.generate(\"I like basketball\", max_length=200)\n",
        "    print(f\"\\n{model_name} output:\")\n",
        "    print(output)\n",
        "\n",
        "    end = time.time()\n",
        "    print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeesqsVOF-0T",
        "outputId": "25952653-9d77-4bd3-9a38-9d0cb7baaf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_medium_en/v1/vocab.json\n",
            "\u001b[1m1042301/1042301\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_medium_en/v1/merges.txt\n",
            "\u001b[1m456318/456318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step       \n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_medium_en/v1/model.h5\n",
            "\u001b[1m1419729400/1419729400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPT"
      ],
      "metadata": {
        "id": "Vq6hrOcnF7dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_list = [\n",
        "    \"opt_125m_en\",\n",
        "    \"opt_1.3b_en\",\n",
        "    \"opt_2.7b_en\",\n",
        "    \"opt_6.7b_en\"\n",
        "]\n",
        "\n",
        "for model_name in model_list:\n",
        "    preprocessor = keras_nlp.models.OPTCausalLMPreprocessor.from_preset(\n",
        "        model_name,\n",
        "        sequence_length=128,\n",
        "    )\n",
        "    tmp_lm = keras_nlp.models.OPTCausalLM.from_preset(\n",
        "        model_name, preprocessor=preprocessor\n",
        "    )\n",
        "\n",
        "    tmp_lm.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=loss,\n",
        "        weighted_metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    tmp_lm.fit(train_ds, epochs=num_epochs)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    output = tmp_lm.generate(\"I like basketball\", max_length=200)\n",
        "    print(f\"\\n{model_name} output:\")\n",
        "    print(output)\n",
        "\n",
        "    end = time.time()\n",
        "    print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
      ],
      "metadata": {
        "id": "Ier45m2eoC41"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mvf-cJ_IaweY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mpKKcd8IiODh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVmKKMeXiTe9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}